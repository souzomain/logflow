# LogFlow: Sistema de ETL para Processamento de Logs

LogFlow √© uma aplica√ß√£o ETL (Extra√ß√£o, Transforma√ß√£o e Carregamento) especializada em processamento de logs, inspirada em ferramentas como Graylog e Logstash. A aplica√ß√£o √© capaz de receber logs de m√∫ltiplas fontes, process√°-los atrav√©s de transforma√ß√µes configur√°veis e encaminh√°-los para diferentes destinos de armazenamento ou an√°lise.

![dashboard](images/dashboard.png)

## Caracter√≠sticas Principais

- Arquitetura modular baseada em plugins
- Suporte para m√∫ltiplas fontes de dados (arquivos, Kafka, S3, etc.)
- Processadores configur√°veis para transforma√ß√£o e filtragem
- M√∫ltiplos destinos para os logs processados (Elasticsearch, OpenSearch, S3, arquivos, etc.)
- API REST para gerenciamento
- Interface de linha de comando
- Alta performance e confiabilidade

## Componentes Dispon√≠veis

### Sources (Fontes)
- **file**: L√™ logs de arquivos locais com suporte a monitoramento cont√≠nuo (tail)
- **kafka**: Consome logs de t√≥picos do Apache Kafka
- **s3**: L√™ logs de buckets do Amazon S3
- **winlog**: L√™ logs de eventos do Windows (Winlogbeat)

### Processors (Processadores)
- **json**: Analisa dados JSON e extrai campos
- **filter**: Filtra eventos com base em condi√ß√µes configur√°veis
- **regex**: Extrai campos usando express√µes regulares
- **grok**: Extrai campos usando padr√µes Grok (similar ao Logstash)
- **mutate**: Modifica campos (adicionar, remover, renomear, converter, etc.)
- **enrich**: Enriquece eventos com dados adicionais (lookup, geolocaliza√ß√£o, etc.)

### Sinks (Destinos)
- **file**: Escreve logs em arquivos locais
- **elasticsearch**: Envia logs para o Elasticsearch
- **opensearch**: Envia logs para o OpenSearch
- **s3**: Armazena logs em buckets do Amazon S3

### Interface Web
O LogFlow inclui uma interface web para monitoramento e gerenciamento de pipelines:

```bash
# Iniciar a interface web
logflow web --port 8080
```

A interface web permite:
- Visualizar o status de todas as pipelines
- Iniciar e parar pipelines
- Monitorar m√©tricas de processamento em tempo real
- Carregar novas configura√ß√µes

## Instala√ß√£o

### Requisitos

- Python 3.9 ou superior
- Poetry

### Instala√ß√£o com Poetry

```bash
# Clonar o reposit√≥rio
git clone https://github.com/organization/logflow.git
cd logflow

# Instalar depend√™ncias
poetry install

# Instalar em modo de desenvolvimento
poetry install --with dev
```

## Uso B√°sico

### Executando com a CLI

```bash
# Usando poetry
poetry run logflow start --config examples/simple.yaml

# Ou ap√≥s ativar o ambiente virtual
logflow start --config examples/simple.yaml
```

### Verificando o Status

```bash
poetry run logflow status
```

### Reiniciando uma Pipeline

```bash
poetry run logflow restart --pipeline simple-pipeline
```

## Configura√ß√£o

LogFlow utiliza arquivos YAML para configura√ß√£o. Um exemplo b√°sico:

```yaml
name: "simple-pipeline"

sources:
  - name: "test-file"
    type: "FileSource"
    config:
      path: "/tmp/test.log"
      tail: true
      read_from_start: true

processors:
  - name: "json-parser"
    type: "JsonProcessor"
    config:
      field: "raw_data"
      target_field: "parsed"
      preserve_original: true
      ignore_errors: true

  - name: "filter-debug"
    type: "FilterProcessor"
    config:
      condition: "level != 'DEBUG'"
      mode: "all"

sinks:
  - name: "file-output"
    type: "FileSink"
    config:
      path: "/tmp/processed.log"
      format: "json"
      append: true

batch_size: 100
batch_timeout: 5.0
```

## API REST

A API REST permite gerenciar o LogFlow programaticamente:

```
GET    /api/v1/pipelines         # Listar todas as pipelines
POST   /api/v1/pipelines         # Criar uma nova pipeline
GET    /api/v1/pipelines/{id}    # Obter detalhes de uma pipeline
DELETE /api/v1/pipelines/{id}    # Remover uma pipeline
POST   /api/v1/pipelines/{id}/start  # Iniciar uma pipeline
POST   /api/v1/pipelines/{id}/stop   # Parar uma pipeline
GET    /api/v1/metrics           # Obter m√©tricas do sistema
```

## Desenvolvimento

### Executando Testes

```bash
poetry run pytest
```

## üìñ Documenta√ß√£o

```bash
poetry run sphinx-build -b html docs/source docs/build
```

## Arquitetura

A arquitetura do LogFlow √© baseada em uma estrutura modular de plugins, dividida em tr√™s componentes principais:

1. **Sources (Fontes)**: Plugins respons√°veis pela obten√ß√£o dos logs de diferentes origens.
2. **Processors (Processadores)**: Componentes que processam, filtram e transformam os dados de log.
3. **Sinks (Destinos)**: Plugins respons√°veis pelo envio dos logs processados para os destinos finais.

## ü§ù Contribuindo

1. Fa√ßa um fork do reposit√≥rio
2. Crie um branch para sua feature (`git checkout -b feature/nova-feature`)
3. Fa√ßa commit das suas mudan√ßas (`git commit -am 'Adiciona nova feature'`)
4. Fa√ßa push para o branch (`git push origin feature/nova-feature`)
5. Crie um novo Pull Request

## üìú Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo LICENSE para detalhes.


## üìà Progress

Veja o progresso do logflow

[![Star History Chart](https://api.star-history.com/svg?repos=souzomain/logflow&type=Date)](https://www.star-history.com/#souzomain/logflow&Date)
